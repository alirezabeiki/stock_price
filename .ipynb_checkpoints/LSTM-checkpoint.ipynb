{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Input Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Reading dataset's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName='Alvand.Tile.csv'\n",
    "stockType='IranStock'  #'Forex'\n",
    "modelType='average'    #'values'\n",
    "look_back=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches=10\n",
    "batch_sizes=32\n",
    "optimizers='adam'\n",
    "losses='mse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readingDataset(fileName, stockType):\n",
    "    \n",
    "    if stockType=='IranStock':\n",
    "        dataset=pd.read_csv(fileName, usecols=[2,3,4,5,7], engine='python')\n",
    "        dataset = dataset.reindex(index = dataset.index[::-1])\n",
    "        print('Shape of dataset: ', dataset.shape)\n",
    "    \n",
    "    if stockType=='Forex':\n",
    "        dataset=pd.read_csv(fileName, usecols=[1,2,3,4,6], engine='python')\n",
    "        dataset = dataset.reindex(index = dataset.index[::-1])\n",
    "        print('Shape of dataset: ', dataset.shape)       \n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=readingDataset(fileName, stockType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHLC_average (dataset):\n",
    "    \n",
    "    if stockType=='IranStock':\n",
    "            OHLC_average = dataset[['Open', 'High', 'Low', 'Close']].mean(axis = 1)\n",
    "    if stockType=='Forex':\n",
    "            OHLC_average = dataset[['Open', 'High', 'Low', 'Close']].mean(axis = 1) \n",
    "    \n",
    "    OHLC_average = OHLC_average.reindex(index = OHLC_average.index[::-1])\n",
    "    OHLC_average = np.reshape(OHLC_average.values, (len(OHLC_average),1))\n",
    "    \n",
    "    return OHLC_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelType=='average':\n",
    "    dataset=OHLC_average(dataset)    \n",
    "  \n",
    "if modelType=='values':\n",
    "    dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Split dataset to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.7)\n",
    "test_size = len(dataset) - train_size\n",
    "print(train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain = dataset[0:train_size]\n",
    "datasetTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTest = dataset[train_size:]\n",
    "datasetTest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcNormalize(data):\n",
    "    scalar = MinMaxScaler()\n",
    "    data=scalar.fit_transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrain = funcNormalize(datasetTrain)\n",
    "datasetTest = funcNormalize(datasetTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataset (data, look_back):\n",
    "    \n",
    "    x=[]\n",
    "    y=[]\n",
    "    \n",
    "    for i in range(look_back, data.shape[0]):\n",
    "        x.append(data[i-look_back:i])\n",
    "        y.append(data[i,0])\n",
    "        \n",
    "    x, y = np.array(x), np.array(y)\n",
    "        \n",
    "    return x, y   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain = generateDataset (datasetTrain, look_back)\n",
    "xtest, ytest = generateDataset (datasetTest, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape of xtrain: ', xtrain.shape, ' and shape of ytrain: ',  ytrain.shape)\n",
    "print('shape of xtest: ', xtest.shape, ' and shape of ytest: ',  ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(50, activation='relu', input_shape=(xtrain.shape[1],xtrain.shape[2]),return_sequences = True))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(60, activation='relu', return_sequences = True))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(80, activation='relu', return_sequences = True))\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(120, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers,loss=losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(xtrain, ytrain, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Evaluate model on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(xtrain)\n",
    "trainPredict[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainPredict, 'blue')\n",
    "plt.plot(datasetTrain[:,0], 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Evaluate model on test ataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(testPredict[:,0], 'blue')\n",
    "plt.plot(ytest, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Future Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFuture=dataset[len(dataset)-look_back:len(dataset)]\n",
    "dataFuture=funcNormalize(dataFuture)\n",
    "dataFuture.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xFuture=[]\n",
    "yy=[]\n",
    "for i in range(look_back, dataFuture.shape[0]):\n",
    "    xFuture.append(dataFuture[i-look_back:i])\n",
    "    #yy.append(dataFuture[i,0])\n",
    "\n",
    "xFuture = np.array(xFuture) \n",
    "#yy = np.array(yy) \n",
    "\n",
    "xFuture.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xFuture=np.expand_dims(xFuture, axis=0)\n",
    "#xFuture.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yFuture=model.predict(xFuture)\n",
    "print('Last day value is: ', xFuture[0,59,0])\n",
    "print('Next day value is: ', yFuture[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yFuture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
